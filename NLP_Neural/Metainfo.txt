Name of QuantLet: NLP_Neural

Published in: Natural Language Processing Introduction - ASE Summer School 2025

Description: 'Implements a simple 2-layer neural network for language modeling. Shows progression from N-grams to neural approaches, includes training visualization, loss curves, and perplexity metrics. Demonstrates backpropagation and gradient descent for text generation tasks.'

Keywords: NLP, neural networks, language modeling, backpropagation, gradient descent, perplexity, deep learning, Shakespeare

See also: NLP_Ngrams, NLP_Embeddings, NLP_Compare, NLP_TokenJourney

Author: Joerg Osterrieder

Submitted: Mon, August 25 2025 by Joerg Osterrieder

Datafiles: shakespeare_sonnets.txt

Output: Training loss curves, perplexity plots, generated text samples, weight visualizations