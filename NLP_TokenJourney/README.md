<div style="margin: 0; padding: 0; text-align: center; border: none;">
<a href="https://quantlet.com" target="_blank" style="text-decoration: none; border: none;">
<img src="https://github.com/StefanGam/test-repo/blob/main/quantlet_design.png?raw=true" alt="Header Image" width="100%" style="margin: 0; padding: 0; display: block; border: none;" />
</a>
</div>

```
Name of QuantLet: NLP_TokenJourney

Published in: Natural Language Processing Introduction - ASE Summer School 2025

Description: Step-by-step visualization of a token journey through a transformer architecture. Shows embedding, positional encoding, multi-head attention, feed-forward networks, and layer normalization. Each transformation is visualized with actual numerical values in 3D space for intuitive understanding.

Keywords: NLP, transformers, attention mechanism, token processing, positional encoding, layer normalization, feed-forward, visualization

See also: NLP_Transformers3D, NLP_TransformersSimple, NLP_TransformersTraining

Author: Joerg Osterrieder

Submitted: Mon, August 25 2025 by Joerg Osterrieder

Datafiles: shakespeare_sonnets.txt

Output: Step-by-step 3D visualizations, attention weight heatmaps, vector transformation animations

```
