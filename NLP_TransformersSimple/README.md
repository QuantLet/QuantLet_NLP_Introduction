<div style="margin: 0; padding: 0; text-align: center; border: none;">
<a href="https://quantlet.com" target="_blank" style="text-decoration: none; border: none;">
<img src="https://github.com/StefanGam/test-repo/blob/main/quantlet_design.png?raw=true" alt="Header Image" width="100%" style="margin: 0; padding: 0; display: block; border: none;" />
</a>
</div>

```
Name of QuantLet: NLP_TransformersSimple

Published in: Natural Language Processing Introduction - ASE Summer School 2025

Description: Minimal transformer implementation focused on clarity and educational value. Implements core components including self-attention, positional encoding, and feed-forward networks with simplified 3D embeddings. Demonstrates transformer principles without mathematical complexity.

Keywords: NLP, transformers, minimal implementation, educational, self-attention, positional encoding, simplified architecture

See also: NLP_TokenJourney, NLP_Transformers3D, NLP_TransformersTraining

Author: Joerg Osterrieder

Submitted: Mon, August 25 2025 by Joerg Osterrieder

Datafiles: shakespeare_sonnets.txt

Output: Simple transformer outputs, attention patterns, component-wise transformations

```
