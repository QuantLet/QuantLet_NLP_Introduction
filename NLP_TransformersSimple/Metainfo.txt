Name of QuantLet: NLP_TransformersSimple

Published in: Natural Language Processing Introduction - ASE Summer School 2025

Description: 'Minimal transformer implementation focused on clarity and educational value. Implements core components including self-attention, positional encoding, and feed-forward networks with simplified 3D embeddings. Demonstrates transformer principles without mathematical complexity.'

Keywords: NLP, transformers, minimal implementation, educational, self-attention, positional encoding, simplified architecture

See also: NLP_TokenJourney, NLP_Transformers3D, NLP_TransformersTraining

Author: Joerg Osterrieder

Submitted: Mon, August 25 2025 by Joerg Osterrieder

Datafiles: shakespeare_sonnets.txt

Output: Simple transformer outputs, attention patterns, component-wise transformations